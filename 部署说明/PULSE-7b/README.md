## <p align="center">ğŸ“£ PULSE-7bæ¨¡å‹å’ŒMedBenchæ•°æ®é›†éƒ¨ç½²è¿‡ç¨‹</p>

## ä¸€ã€å®˜æ–¹ç½‘é¡µDemoæ–¹å¼éƒ¨ç½²æµç¨‹
- æ‹‰å–PULSE-7bv5æ¨¡å‹
    ```bash
    hf-cli --model-id OpenMEDLab/PULSE-7bv5
    ```
- æ‹‰å–gitä»“åº“å¹¶åˆ›å»ºcondaç¯å¢ƒ
    ```bash
    git clone https://github.com/openmedlab/PULSE.git
    cd PULSE
    conda env create -f llm.yml
    conda activate llm
    ```
- ä¿®æ”¹`web_demo_gradio.py`è„šæœ¬
    <br>è®¾ç½®è¿è¡Œç¯å¢ƒï¼š
    ```python
    parser = argparse.ArgumentParser()
    ## ä¿®æ”¹è·¯å¾„ï¼Œdefault=""ä¸­æ›¿æ¢ä¸ºæœ¬æœºä¸­çš„PULSE-7bv5æ¨¡å‹è·¯å¾„
    parser.add_argument("--model_name", default="OpenMEDLab/PULSE-7bv5", type=str)  
    ## è®¾ç½®GPUæ•°é‡å’Œç¼–å·ï¼Œä¾‹å¦‚è®¾ç½® default="0,1" è¡¨ç¤ºæ¨¡å‹è¿è¡Œåœ¨åŒå¡ä¸Šï¼Œnvidia-smiå‘½ä»¤æŸ¥çœ‹æ˜¾å¡ç¼–å·
    parser.add_argument("--gpu", default="0", type=str)
    parser.add_argument("--input_max_len", default=1536, type=int)
    args = parser.parse_args()
    ```
    <br>è§£å†³PyTorchæ˜¾å­˜ç¢ç‰‡åŒ–é—®é¢˜ï¼š
    ```python
    ## æ·»åŠ ä¸‹è¡Œä»£ç ï¼š
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64"
    ```
    <br>è®¾ç½®batch_sizeå¤§å°ï¼š
    ```python
    ## æ·»åŠ ï¼š
    batch_size = 1
    ```
- æ‰§è¡Œ`python web_demo_gradio.py`å¯åŠ¨æ¨¡å‹

## äºŒã€å°æ˜¾å­˜GPUçš„é‡åŒ–è¿è¡Œæ–¹æ³•
1. huggingfaceå®˜æ–¹æŒ‡å—ä¸­æä¾›çš„é‡åŒ–æ–¹æ³•
<br>[transformersä¸­é›†æˆçš„é‡åŒ–åº“](https://huggingface.co/docs/transformers/quantization)
<br>[é‡åŒ–Transformersæ¨¡å‹](https://huggingface.co/docs/transformers/main/zh/main_classes/quantization)
<br>[ç”¨ bitsandbytesã€4 æ¯”ç‰¹é‡åŒ–å’Œ QLoRA æ‰“é€ äº²æ°‘çš„ LLM](https://huggingface.co/blog/zh/4bit-transformers-bitsandbytes)

2. é€‰æ‹©bitsandbytesåŠ è½½PULSE-7bv5æ¨¡å‹
- ç¡®ä¿åº“çš„å®Œæ•´å®‰è£…ï¼š
    ```python
    conda activate llm
    pip install bitsandbytes>=0.39.0
    pip install --upgrade accelerate
    pip install --upgrade transformers
    ```
- è°ƒæ•´`web_demo_gradio.py`è„šæœ¬ï¼Œè®¾ç½®int4é‡åŒ–ï¼š
    ```python
    ## å¯ç”¨BitsAndBytesConfigåº“
    from transformers import BitsAndBytesConfig
    ```
    ```python
    ## é…ç½®int4é‡åŒ–å‚æ•°
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_compute_dtype=torch.bfloat16,
    )

    ## æ¨¡å‹åŠ è½½
    model = AutoModelForCausalLM.from_pretrained(
        args.model_name, 
        torch_dtype=torch.bfloat16,
        quantization_config=bnb_config, ## åŠ è½½é‡åŒ–
        device_map="auto",
    ).eval()
    ```

3. é…ç½®å‚è€ƒ
    <br>![é…ç½®å‚è€ƒ](web_demo.png)
    
    >batch size=1æ—¶æœ¬åœ°éƒ¨ç½²PULSEè¿›è¡Œæ¨ç†æ‰€éœ€çš„æ˜¾å­˜å¤§å°ã€‚
    >|æ¨¡å‹å‚æ•°| é‡åŒ–ç­‰çº§ | åŠ è½½æ¨¡å‹ |
    >| -------- | -------- | -------- |
    >|7B        | FP16     | 14GB     |
    >|7B        | INT4     | 6GB      |

## ä¸‰ã€åœ¨OpenCompassä¸­æ·»åŠ å¹¶è¿è¡Œæ¨ç†çš„è¿‡ç¨‹
### MedBenchæ•°æ®é›†çš„å‡†å¤‡
- ä¸‹è½½æ•°æ®é›†
```bash
## medbenchå®˜ç½‘æ•°æ®é›†(3.8mb) æœ¬ä»“åº“å·²ç»é›†æˆ
wget https://cdn-static.openxlab.org.cn/medical/MedBench.zip
## opencompassæ•°æ®é›†(51.6mb)
wget https://github.com/QXY716/opencompass/releases/download/OpenCompassData/Medbench.zip
```
- è§£å‹è‡³opencompass/dataæ–‡ä»¶å¤¹å†…
```bash
unzip MedBench.zip
```
- ä¿®æ”¹æ•°æ®é›†åŠ è½½æ–¹å¼ï¼ˆcloneæœ¬ä»“åº“å¯å¿½ç•¥ï¼‰ï¼š
<br>https://github.com/QXY716/opencompass/commit/65695c08d0eee6f7a641ab08bdd710131dafdbf8
<br>https://github.com/QXY716/opencompass/commit/315fbe0699e9d28cd14ff063f6a0dbeb3ad39977


### PULSE-7bæ·»åŠ æ”¯æŒæ–¹æ³•
- åœ¨`opencompass/configs/models/`ä¸‹æ–°å»º`/pulse/hf_pulse_7b.py`ï¼Œå¹¶æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
```python
from opencompass.models import HuggingFaceCausalLM
import torch

models = [
    dict(
        type=HuggingFaceCausalLM,
        abbr='PULSE-7bv5',
        path='/home/dongru/PULSE-7bv5',  ##æ¨¡å‹è·¯å¾„
        tokenizer_path='/home/dongru/PULSE-7bv5',  ##æ¨¡å‹è·¯å¾„
        model_kwargs=dict(
            trust_remote_code=True,
            torch_dtype=torch.bfloat16,
            ## load_in_4bit=True,
            device_map='auto',
        ),
        tokenizer_kwargs=dict(
            trust_remote_code=True,
        ),
        max_out_len=1024,
        batch_size=1,
        run_cfg=dict(num_gpus=2),
    )
]

```
### è¿è¡Œè¯„ä¼°
```bash
CUDA_VISIBLE_DEVICES=0,1 python run.py --models hf_pulse_7b  --datasets medbench_gen --debug
```
